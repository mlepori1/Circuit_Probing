# Model
model_type: "gpt_neox"
model_path: "EleutherAI/pythia-160m"
random_init: False
reinit_embeddings: False
layer_reinit: True
target_layer_list: [0, 1, 2, 3, 4, 5]
operation_list: ["attn", "mlp"]
updates: True
residual: False
intermediate_size: -1
n_classes: 50

# Data
train_data_path: "../data/ud-treebanks-conll2017/UD_English/en-ud-train.conllu"
lm_data_path: "../data/ud-treebanks-conll2017/UD_English/en-ud-dev.conllu"
label: "dep"
train_size: 1000
dev_size: 100
test_size: 1000

# Training
num_epochs: 15
lr_list: [0.01]
batch_size_list: [16]
data_seed: 0
model_seed_list: [0, 1, 2]

# Output
model_dir: "../Models/"
results_dir: "../Results/Baseline/Pythia160M/Dep/rand-layer-dep"
save_models: False